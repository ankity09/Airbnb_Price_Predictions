cat("\nRan successfully with 4 +",i,"nodes.")
}
for(i in 1:4){
cat("\nTRAIN DATA: Error rate with 4 +",i, " nodes: ", df.train.nn.error[i])
}
for(i in 1:4){
nntemp <- neuralnet(SW ~ VACATION + SLOT + DISTANCE + FARE + HI + GATE + PAX, hidden = c(4,i), data = df.train, err.fct = "ce", linear.output = F, threshold = 0.1)
nntemp.test.predict <- compute(nntemp, df.test[colseq])$net.result
nntemp.test.predict.final <- ifelse(nntemp.test.predict>0.5,1,0)
df.test.nn.error[i] <- 1-(sum(df.test$SW == nntemp.test.predict.final)/nrow(df.test))
cat("\nRan successfully with 4 +",i,"nodes.")
}
for(i in 1:4){
cat("\nTEST DATA: Error rate with 4 +",i, " nodes: ", df.test.nn.error[i])
}
### Q4 E ### --- ROC ---
set.seed(13)
### Q4 E ### --- ROC ---
nn <- neuralnet(SW ~ VACATION + SLOT + DISTANCE + FARE + HI + GATE + PAX, data = df.train, hidden=c(4), err.fct="ce", linear.output = F)
plot(nn)
nn.test.predict <- compute(nn, df.test[colseq])$net.result
#
df.rocr.logmodel <- data.frame(logmodel.test.predict, df.test$SW)
df.rocr.nn <- data.frame(nn.test.predict, df.test$SW)
#
pred.rocr.logmodel <- prediction(logmodel.test.predict, df.test$SW)
perf.rocr.logmodel <- performance(pred.rocr.logmodel, "tpr", "fpr")
#
pred.rocr.nn <- prediction(nn.test.predict, df.test$SW)
perf.rocr.nn <- performance(pred.rocr.nn, "tpr", "fpr")
#
plot(perf.rocr.logmodel, col="red", main="ROC CURVES")
plot(perf.rocr.nn, add=TRUE, col="blue")
abline(a=0, b= 1, lty=2)
## Add Legend
legend("bottomright", c("Logistic Model", "Neural Model"), lty=1,
col = c("red", "blue"), bty="n")
### Q5 A ### --- Train Data ---
linfaremodel <- lm(FARE ~ SW + VACATION + SLOT + DISTANCE + HI + GATE + PAX, data = df.train)
linfaremodel.train.predict <- predict(linfaremodel, newdata = df.train)
rmse(df.train$FARE, linfaremodel.train.predict)
### Q5 A ### --- Test Data ---
linfaremodel.test.predict <- predict(linfaremodel, newdata = df.test)
rmse(df.test$FARE, linfaremodel.test.predict)
### Q5 B ###
nn2 <- neuralnet(FARE ~ SW + VACATION + SLOT + DISTANCE + HI + GATE + PAX, hidden = c(4), data = df.train, err.fct = "sse", linear.output = T)
plot(nn2)
### Q5 C ### --- Train Data ---
nn2.predicted.fare.train <- compute(nn2, df.train[fcolseq])$net.result
rmse(df.train$FARE, nn2.predicted.fare.train)
### Q5 C ### --- Train Data ---
nn2.predicted.fare.test <- compute(nn2, df.test[fcolseq])$net.result
rmse(df.test$FARE, nn2.predicted.fare.test)
### Q5 D ###
nn2.predicted.rmse.train <- NULL
nn2.predicted.rmse.test <- NULL
############
for(i in 0:7){
nn2temp <- neuralnet(FARE ~ SW + VACATION + SLOT + DISTANCE + HI + GATE + PAX, hidden = c(i), data = df.train, err.fct = "sse", linear.output = T)
nn2.predicted.fare.train <- compute(nn2temp, df.train[fcolseq])$net.result
nn2.predicted.rmse.train[i+1] <- rmse(df.train$FARE, nn2.predicted.fare.train)
cat("\nRan successfully with",i,"nodes.")
}
for(i in 0:7){
cat("\nTRAIN DATA: RMSE with ",i, " nodes: ", nn2.predicted.rmse.train[i+1])
}
for(i in 0:7){
nn2temp <- neuralnet(FARE ~ SW + VACATION + SLOT + DISTANCE + HI + GATE + PAX, hidden = c(i), data = df.train, err.fct = "sse", linear.output = T)
nn2.predicted.fare.test <- compute(nn2temp, df.test[fcolseq])$net.result
nn2.predicted.rmse.test[i+1] <- rmse(df.test$FARE, nn2.predicted.fare.test)
cat("\nRan successfully with",i,"nodes.")
}
for(i in 0:7){
cat("\nTEST DATA: RMSE with ",i, " nodes: ", nn2.predicted.rmse.test[i+1])
}
for(i in 1:4){
nn2temp <- neuralnet(FARE ~ SW + VACATION + SLOT + DISTANCE + HI + GATE + PAX, hidden = c(4,i), data = df.train, err.fct = "sse", linear.output = T)
nn2.predicted.fare.train <- compute(nn2temp, df.train[fcolseq])$net.result
nn2.predicted.rmse.train[i] <- rmse(df.train$FARE, nn2.predicted.fare.train)
cat("\nRan successfully with 4 +",i,"nodes.")
}
for(i in 1:4){
cat("\nTRAIN DATA: RMSE with 4 +",i, " nodes: ", nn2.predicted.rmse.train[i])
}
for(i in 1:4){
nn2temp <- neuralnet(FARE ~ SW + VACATION + SLOT + DISTANCE + HI + GATE + PAX, hidden = c(4,i), data = df.train, err.fct = "sse", linear.output = T)
nn2.predicted.fare.test <- compute(nn2temp, df.test[fcolseq])$net.result
nn2.predicted.rmse.test[i] <- rmse(df.test$FARE, nn2.predicted.fare.test)
cat("\nRan successfully with 4 +",i,"nodes.")
}
for(i in 1:4){
cat("\nTEST DATA: RMSE with 4 +",i, " nodes: ", nn2.predicted.rmse.test[i])
}
### LIBRARIES ###
library(neuralnet)
library(Metrics)
library(ROCR)
colseq <- c(1,4,6,8,3,5,7)
fcolseq <- c(2,1,4,6,3,5,7)
#################
### Q1 A ###
Airline.Data.V2 <- read.csv("Airline Data V2.csv")
df <- na.omit(data.frame(Airline.Data.V2))
df <- df[,-c(1:6,10:13)]
### Q1 B ###
### BINARY DUMMY VARIABLES ###
df$VACATION <- as.numeric(df$VACATION)-1 #no=0; yes =1
df$SW <- as.numeric(df$SW)-1 #no=0; yes =1
df$SLOT <- as.numeric(df$SLOT)-1 #controlled = 0; free =1
df$GATE <- as.numeric(df$GATE)-1 #constrained = 0; free =1
### Q1 C ###
range01 <- function(x){(x-min(x))/(max(x)-min(x))}
df$FARE <- range01(df$FARE)
df$DISTANCE <- range01(df$DISTANCE)
df$HI <- range01(df$HI)
df$PAX <- range01(df$PAX)
### Q1 D ###
df <- na.omit(df)
### Q1 E ###
set.seed(71923)
### Q1 F ###
splitter <- sample(nrow(df),0.6*nrow(df))
df.train <- df[splitter,]
df.test <- df[-splitter,]
### Q2 A ###
logmodel <- glm(SW ~ VACATION + SLOT + FARE + DISTANCE + HI + GATE + PAX, data = df.train, family = "binomial")
summary(logmodel)
### Q2 B ### ---Confusion Matrix---
logmodel.train.predict <- predict(logmodel, type = "response")
log.train.predict.final <- ifelse(logmodel.train.predict>0.5,1,0)
df.train.predict.table <- table(df.train$SW, log.train.predict.final)
df.train.predict.table
### Q2 B ### ---Confusion Matrix---
logmodel.test.predict <- predict(logmodel, newdata = df.test, type = "response")
log.test.predict.final <- ifelse(logmodel.test.predict>0.5,1, 0)
df.test.predict.table <- table(df.test$SW, log.test.predict.final)
df.test.predict.table
### Q2 B ### ---Metrics---
perfomrance.metrics <- function(x,y,z){
metrics <- c('Sensitivity','Specificity','Accuracy','Error Rate', 'PPV','NP')
sens <- sum(x == 1 & y == 1)/sum(x == 1)
speci <- sum(x == 0 & y == 0)/sum(x == 0)
acc <- sum(x == y)/nrow(z)
er <- 1 - acc
ppv <- sum(x == 1 & y == 1)/sum(y == 1)
npv <- sum(x == 0 & y == 0)/sum(y == 0)
values <- c(sens,speci,acc,er,ppv,npv)
X <- data.frame(metrics,values)
X
}
perfomrance.metrics(df.train$SW, log.train.predict.final, df.train)
perfomrance.metrics(df.test$SW, log.test.predict.final, df.test)
### Q3 ### ---Prep---
set.seed(13)
### Q3 A ###
nn <- neuralnet(SW ~ VACATION + SLOT + DISTANCE + FARE + HI + GATE + PAX, hidden = c(4), data = df.train, err.fct = "ce", linear.output = F)
plot(nn)
### Q3 B ### ---TRAIN Confusion Matrix---
nn.train.predict <- compute(nn, df.train[colseq])$net.result
nn.train.predict.final <- ifelse(nn.train.predict>0.5,1,0)
df.train.predict.nn.table <- table(df.train$SW, nn.train.predict.final)
df.train.predict.nn.table
### Q3 B ### ---TEST Confusion Matrix---
nn.test.predict <- compute(nn, df.test[colseq])$net.result
nn.test.predict.final <- ifelse(nn.test.predict>0.5,1,0)
df.test.predict.nn.table <- table(df.test$SW, nn.test.predict.final)
df.test.predict.nn.table
### Q3 C ###
perfomrance.metrics(df.train$SW, nn.train.predict.final, df.train)
perfomrance.metrics(df.test$SW, nn.test.predict.final, df.test)
### Q3 D ###
#OBSERVATION
############
### Q4 A ###
df.train.nn.error <- NULL
df.test.nn.error <- NULL
############
for(i in 0:7){
nntemp <- neuralnet(SW ~ VACATION + SLOT + DISTANCE + FARE + HI + GATE + PAX, hidden = c(i), data = df.train, err.fct = "ce", linear.output = F, stepmax = 1e6)
nntemp.train.predict <- compute(nntemp, df.train[colseq])$net.result
nntemp.train.predict.final <- ifelse(nntemp.train.predict>0.5,1,0)
df.train.nn.error[i+1] <- 1-(sum(df.train$SW == nntemp.train.predict.final)/nrow(df.train))
cat("\nRan successfully with",i,"nodes.")
}
#
for(i in 0:7){
cat("\nTRAIN DATA: Error rate with ",i, " nodes: ", df.train.nn.error[i+1])
}
#
for(i in 0:7){
nntemp <- neuralnet(SW ~ VACATION + SLOT + DISTANCE + FARE + HI + GATE + PAX, hidden = c(i), data = df.train, err.fct = "ce", linear.output = F, stepmax = 1e6)
nntemp.test.predict <- compute(nntemp, df.test[colseq])$net.result
nntemp.test.predict.final <- ifelse(nntemp.test.predict>0.5,1,0)
df.test.nn.error[i+1] <- 1-(sum(df.test$SW == nntemp.test.predict.final)/nrow(df.test))
cat("\nRan successfully with",i,"nodes.")
}
#
for(i in 0:7){
cat("\nTEST DATA: Error rate with ",i, " nodes: ", df.test.nn.error[i+1])
}
#
### Q4 B ###
df.train.nn.error <- NULL
df.test.nn.error <- NULL
############
for(i in 1:4){
nntemp <- neuralnet(SW ~ VACATION + SLOT + DISTANCE + FARE + HI + GATE + PAX, hidden = c(4,i), data = df.train, err.fct = "ce", linear.output = F, threshold = 0.1)
nntemp.train.predict <- compute(nntemp, df.train[colseq])$net.result
nntemp.train.predict.final <- ifelse(nntemp.train.predict>0.5,1,0)
df.train.nn.error[i] <- 1-(sum(df.train$SW == nntemp.train.predict.final)/nrow(df.train))
cat("\nRan successfully with 4 +",i,"nodes.")
}
#
for(i in 1:4){
cat("\nTRAIN DATA: Error rate with 4 +",i, " nodes: ", df.train.nn.error[i])
}
#
for(i in 1:4){
nntemp <- neuralnet(SW ~ VACATION + SLOT + DISTANCE + FARE + HI + GATE + PAX, hidden = c(4,i), data = df.train, err.fct = "ce", linear.output = F, threshold = 0.1)
nntemp.test.predict <- compute(nntemp, df.test[colseq])$net.result
nntemp.test.predict.final <- ifelse(nntemp.test.predict>0.5,1,0)
df.test.nn.error[i] <- 1-(sum(df.test$SW == nntemp.test.predict.final)/nrow(df.test))
cat("\nRan successfully with 4 +",i,"nodes.")
}
#
for(i in 1:4){
cat("\nTEST DATA: Error rate with 4 +",i, " nodes: ", df.test.nn.error[i])
}
#
### Q4 C ###
#OBSERVATION
############
### Q4 D ###
#OBSERVATION
############
### Q4 E ### --- ROC ---
nn <- neuralnet(SW ~ VACATION + SLOT + DISTANCE + FARE + HI + GATE + PAX, data = df.train, hidden=c(4), err.fct="ce", linear.output = F)
plot(nn)
nn.test.predict <- compute(nn, df.test[colseq])$net.result
#
df.rocr.logmodel <- data.frame(logmodel.test.predict, df.test$SW)
df.rocr.nn <- data.frame(nn.test.predict, df.test$SW)
#
pred.rocr.logmodel <- prediction(logmodel.test.predict, df.test$SW)
perf.rocr.logmodel <- performance(pred.rocr.logmodel, "tpr", "fpr")
#
pred.rocr.nn <- prediction(nn.test.predict, df.test$SW)
perf.rocr.nn <- performance(pred.rocr.nn, "tpr", "fpr")
#
plot(perf.rocr.logmodel, col="red", main="ROC CURVES")
plot(perf.rocr.nn, add=TRUE, col="blue")
abline(a=0, b= 1, lty=2)
### Add Legend ###
legend("bottomright", c("Logistic Model", "Neural Model"), lty=1,
col = c("red", "blue"), bty="n")
##################
### Q5 A ### --- Train Data ---
linfaremodel <- lm(FARE ~ SW + VACATION + SLOT + DISTANCE + HI + GATE + PAX, data = df.train)
linfaremodel.train.predict <- predict(linfaremodel, newdata = df.train)
rmse(df.train$FARE, linfaremodel.train.predict)
### Q5 A ### --- Test Data ---
linfaremodel.test.predict <- predict(linfaremodel, newdata = df.test)
rmse(df.test$FARE, linfaremodel.test.predict)
### Q5 B ###
nn2 <- neuralnet(FARE ~ SW + VACATION + SLOT + DISTANCE + HI + GATE + PAX, hidden = c(4), data = df.train, err.fct = "sse", linear.output = T)
plot(nn2)
### Q5 C ### --- Train Data ---
nn2.predicted.fare.train <- compute(nn2, df.train[fcolseq])$net.result
rmse(df.train$FARE, nn2.predicted.fare.train)
### Q5 C ### --- Train Data ---
nn2.predicted.fare.test <- compute(nn2, df.test[fcolseq])$net.result
rmse(df.test$FARE, nn2.predicted.fare.test)
### Q5 D ###
nn2.predicted.rmse.train <- NULL
nn2.predicted.rmse.test <- NULL
############
for(i in 0:7){
nn2temp <- neuralnet(FARE ~ SW + VACATION + SLOT + DISTANCE + HI + GATE + PAX, hidden = c(i), data = df.train, err.fct = "sse", linear.output = T)
nn2.predicted.fare.train <- compute(nn2temp, df.train[fcolseq])$net.result
nn2.predicted.rmse.train[i+1] <- rmse(df.train$FARE, nn2.predicted.fare.train)
cat("\nRan successfully with",i,"nodes.")
}
#
for(i in 0:7){
cat("\nTRAIN DATA: RMSE with ",i, " nodes: ", nn2.predicted.rmse.train[i+1])
}
#
for(i in 0:7){
nn2temp <- neuralnet(FARE ~ SW + VACATION + SLOT + DISTANCE + HI + GATE + PAX, hidden = c(i), data = df.train, err.fct = "sse", linear.output = T)
nn2.predicted.fare.test <- compute(nn2temp, df.test[fcolseq])$net.result
nn2.predicted.rmse.test[i+1] <- rmse(df.test$FARE, nn2.predicted.fare.test)
cat("\nRan successfully with",i,"nodes.")
}
#
for(i in 0:7){
cat("\nTEST DATA: RMSE with ",i, " nodes: ", nn2.predicted.rmse.test[i+1])
}
#
for(i in 1:4){
nn2temp <- neuralnet(FARE ~ SW + VACATION + SLOT + DISTANCE + HI + GATE + PAX, hidden = c(4,i), data = df.train, err.fct = "sse", linear.output = T)
nn2.predicted.fare.train <- compute(nn2temp, df.train[fcolseq])$net.result
nn2.predicted.rmse.train[i] <- rmse(df.train$FARE, nn2.predicted.fare.train)
cat("\nRan successfully with 4 +",i,"nodes.")
}
#
for(i in 1:4){
cat("\nTRAIN DATA: RMSE with 4 +",i, " nodes: ", nn2.predicted.rmse.train[i])
}
#
for(i in 1:4){
nn2temp <- neuralnet(FARE ~ SW + VACATION + SLOT + DISTANCE + HI + GATE + PAX, hidden = c(4,i), data = df.train, err.fct = "sse", linear.output = T)
nn2.predicted.fare.test <- compute(nn2temp, df.test[fcolseq])$net.result
nn2.predicted.rmse.test[i] <- rmse(df.test$FARE, nn2.predicted.fare.test)
cat("\nRan successfully with 4 +",i,"nodes.")
}
#
for(i in 1:4){
cat("\nTEST DATA: RMSE with 4 +",i, " nodes: ", nn2.predicted.rmse.test[i])
}
### EOF ###
### LIBRARIES ###
library(neuralnet)
library(Metrics)
library(ROCR)
colseq <- c(1,4,6,8,3,5,7)
fcolseq <- c(2,1,4,6,3,5,7)
#################
### Q1 A ###
Airline.Data.V2 <- read.csv("Airline Data V2.csv")
df <- na.omit(data.frame(Airline.Data.V2))
df <- df[,-c(1:6,10:13)]
### Q1 B ###
### BINARY DUMMY VARIABLES ###
df$VACATION <- as.numeric(df$VACATION)-1 #no=0; yes =1
df$SW <- as.numeric(df$SW)-1 #no=0; yes =1
df$SLOT <- as.numeric(df$SLOT)-1 #controlled = 0; free =1
df$GATE <- as.numeric(df$GATE)-1 #constrained = 0; free =1
### Q1 C ###
range01 <- function(x){(x-min(x))/(max(x)-min(x))}
df$FARE <- range01(df$FARE)
df$DISTANCE <- range01(df$DISTANCE)
df$HI <- range01(df$HI)
df$PAX <- range01(df$PAX)
### Q1 D ###
df <- na.omit(df)
### Q1 E ###
set.seed(71923)
### Q1 F ###
splitter <- sample(nrow(df),0.6*nrow(df))
df.train <- df[splitter,]
df.test <- df[-splitter,]
### Q2 A ###
logmodel <- glm(SW ~ VACATION + SLOT + FARE + DISTANCE + HI + GATE + PAX, data = df.train, family = "binomial")
summary(logmodel)
### Q2 B ### ---Confusion Matrix---
logmodel.train.predict <- predict(logmodel, type = "response")
log.train.predict.final <- ifelse(logmodel.train.predict>0.5,1,0)
df.train.predict.table <- table(df.train$SW, log.train.predict.final)
df.train.predict.table
### Q2 B ### ---Confusion Matrix---
logmodel.test.predict <- predict(logmodel, newdata = df.test, type = "response")
log.test.predict.final <- ifelse(logmodel.test.predict>0.5,1, 0)
df.test.predict.table <- table(df.test$SW, log.test.predict.final)
df.test.predict.table
### Q2 B ### ---Metrics---
perfomrance.metrics <- function(x,y,z){
metrics <- c('Sensitivity','Specificity','Accuracy','Error Rate', 'PPV','NP')
sens <- sum(x == 1 & y == 1)/sum(x == 1)
speci <- sum(x == 0 & y == 0)/sum(x == 0)
acc <- sum(x == y)/nrow(z)
er <- 1 - acc
ppv <- sum(x == 1 & y == 1)/sum(y == 1)
npv <- sum(x == 0 & y == 0)/sum(y == 0)
values <- c(sens,speci,acc,er,ppv,npv)
X <- data.frame(metrics,values)
X
}
perfomrance.metrics(df.train$SW, log.train.predict.final, df.train)
perfomrance.metrics(df.test$SW, log.test.predict.final, df.test)
### LIBRARIES ###
library(neuralnet)
library(Metrics)
library(ROCR)
colseq <- c(1,4,6,8,3,5,7)
fcolseq <- c(2,1,4,6,3,5,7)
#################
### Q1 A ###
Airline.Data.V2 <- read.csv("Airline Data V2.csv")
df <- na.omit(data.frame(Airline.Data.V2))
df <- df[,-c(1:6,10:13)]
### Q1 B ###
### BINARY DUMMY VARIABLES ###
df$VACATION <- as.numeric(df$VACATION)-1 #no=0; yes =1
df$SW <- as.numeric(df$SW)-1 #no=0; yes =1
df$SLOT <- as.numeric(df$SLOT)-1 #controlled = 0; free =1
df$GATE <- as.numeric(df$GATE)-1 #constrained = 0; free =1
### Q1 C ###
range01 <- function(x){(x-min(x))/(max(x)-min(x))}
df$FARE <- range01(df$FARE)
df$DISTANCE <- range01(df$DISTANCE)
df$HI <- range01(df$HI)
df$PAX <- range01(df$PAX)
### Q1 D ###
df <- na.omit(df)
### Q1 E ###
set.seed(71923)
### Q1 F ###
splitter <- sample(nrow(df),0.6*nrow(df))
df.train <- df[splitter,]
df.test <- df[-splitter,]
setwd("C:/Users/jayse/Desktop/NYC Airbnb")
### Libraries
install.packages("fread")
library(fread)
### Data Import
dlistings <- fread("listings.csv.gz")
library(R.utils)
install.packages("R.utils")
library(R.utils)
### Data Import
dlistings <- fread("listings.csv.gz")
library(data.table)
### Data Import
dlistings <- fread("listings.csv.gz")
### Data Import
dlistings <- fread("listings.csv.gz", sep = ",")
### Data Import
slistings <- read.csv("listings.csv")
str(slistings)
sreviews.csv <- read.csv("reviews.csv")
str(sreviews.csv)
sreviews <- read.csv("reviews.csv")
str(sreviews)
dlistings <- read.csv("listings.csv")
df <- dlistings
str(df)
View(df)
df <- df[,-c(1:22)]
df
View(df)
df <- dlistings
View(df)
df <- df[,c(23,24,26,27,29,33,34,37,46,52,53,54,55,56,57,59,61:69,78:81,83,84,87,98,99,106)]
colnames(df)
plot(df[],df[])
plot(df)
cor(df)
cor(df)
cor(df$accommodates,df$guests_included)
cor(df$accommodates,df$extra_people)
df$extra_people
str(df$extra_people)
df$extra_people <- as.numeric(df$extra_people)
cor(df$accommodates,df$extra_people)
df$extra_people
df <- dlistings
str(df)
df <- df[,c(23,24,26,27,29,33,34,37,46,52,53,54,55,56,57,59,61:69,78:81,83,84,87,98,99,106),]
df$extra_people <- as.numeric(df$extra_people)
colnames(df)
df <- dlistings
str(df)
df <- df[,c(23,24,26,27,29,33,34,37,46,52,53,54,55,56,57,59,61:69,78:81,83,84,87,98,99,106),]
df$extra_people
df$extra_people <- gsub(pattern="$", replacement = "", x = df$extra_people)
df$extra_people <- as.numeric(df$extra_people)
cor(df$accommodates,df$extra_people)
df <- dlistings
str(df)
df <- df[,c(23,24,26,27,29,33,34,37,46,52,53,54,55,56,57,59,61:69,78:81,83,84,87,98,99,106),]
df$extra_people <- as.numeric(gsub("\\$", "", df$extra_people))
cor(df$accommodates,df$extra_people)
df$extra_people
cor(df$accommodates,df$guests_included)
cor(df$number_of_reviews_ltm, df$reviews_per_month)
df$number_of_reviews_ltm
df$reviews_per_month
class(df$reviews_per_month)
class(df$number_of_reviews_ltm)
df$number_of_reviews_ltm <- as.numeric(df$number_of_reviews_ltm)
cor(df$number_of_reviews_ltm, df$reviews_per_month)
class(df$number_of_reviews_ltm)
class(df$reviews_per_month)
df$reviews_per_month
df$number_of_reviews_ltm
mean(df$number_of_reviews_ltm)
mean(dlistings$number_of_reviews_ltm)
fit1 <- lm(df$price~.)
fit1 <- lm(df$price~., data = df)
fit1 <- lm(price~., data = df)
fit1
fit1 <- lm(price~accomodates + bathrooms + bedrooms + beds, data = df)
fit1 <- lm(price~accommodates + bathrooms + bedrooms + beds, data = df)
df$price <- as.numeric(df$price)
fit1 <- lm(price~accommodates + bathrooms + bedrooms + beds, data = df)
summary(fit1)
df <- dlistings
str(df)
df <- df[,c(23,24,26,27,29,33,34,37,46,52,53,54,55,56,57,59,61:69,78:81,83,84,87,98,99,106),]
df$price
df$price <- as.numeric(gsub("\\$", "", df$price))
df <- dlistings
str(df)
df <- df[,c(23,24,26,27,29,33,34,37,46,52,53,54,55,56,57,59,61:69,78:81,83,84,87,98,99,106),]
df$price
df$price
df$price <- as.numeric(gsub("\\$", "", df$price))
df$price
df <- df[,c(23,24,26,27,29,33,34,37,46,52,53,54,55,56,57,59,61:69,78:81,83,84,87,98,99,106),]
df <- dlistings
df <- df[,c(23,24,26,27,29,33,34,37,46,52,53,54,55,56,57,59,61:69,78:81,83,84,87,98,99,106)]
df$extra_people <- as.numeric(gsub("\\$", "", df$extra_people))
